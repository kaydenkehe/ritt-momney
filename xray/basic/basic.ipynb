{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic\n",
    "\n",
    "Just optimize for high/low biological age. Nicer version of exploration/naive_attempt.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# allow helper import\n",
    "import sys\n",
    "sys.path.append('../../assets/scripts')\n",
    "\n",
    "from cheff import CheffAEModel\n",
    "from cxrage import load_model, age_fn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import to_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "# load LDM\n",
    "sdm_path = '../../assets/models/cheff_diff_uncond.pt'\n",
    "ae_path = '../../assets/models/cheff_autoencoder.pt'\n",
    "cheff_ae = CheffAEModel(model_path=ae_path, device=device)\n",
    "\n",
    "# load cxr-age\n",
    "cxr_age = load_model(path='../../assets/')\n",
    "cxr_age.model.to(device)\n",
    "\n",
    "# load, encode sample images\n",
    "sample_imgs = [Image.open(f'../../assets/cxrs/nih/ae_nih{i}.png') for i in range(1, 6)]\n",
    "with torch.no_grad():\n",
    "    lreps = [cheff_ae.encode(to_tensor(img).unsqueeze(0).to(device)) for img in sample_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incentivize high outputs (by default)\n",
    "def loss_fn(a, pred, b, lrep):\n",
    "    output_l = pred\n",
    "    kl = torch.mean(0.5 * torch.sum(lrep**2 - 1 - torch.log(lrep**2), dim=1))\n",
    "    return -a * output_l + b * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available RAM: 3.14 GB\n",
      "Available VRAM: 3.00 GB\n"
     ]
    }
   ],
   "source": [
    "# check available ram\n",
    "import psutil\n",
    "print(f'Available RAM: {psutil.virtual_memory().available / 1e9:.2f} GB')\n",
    "\n",
    "# check available vram\n",
    "import pynvml\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "print(f'Available VRAM: {info.free / 1e9:.2f} GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1/5:\n",
      "Epoch 1/10 | Age: 84.04\n",
      "Epoch 2/10 | Age: 66.28\n",
      "Epoch 3/10 | Age: 55.89\n",
      "Epoch 4/10 | Age: 49.53\n",
      "Epoch 5/10 | Age: 44.61\n",
      "Epoch 6/10 | Age: 40.36\n",
      "Epoch 7/10 | Age: 35.99\n",
      "Epoch 8/10 | Age: 32.06\n",
      "Epoch 9/10 | Age: 29.22\n",
      "Epoch 10/10 | Age: 26.28\n",
      "\n",
      "Image 2/5:\n",
      "Epoch 1/10 | Age: 77.68\n",
      "Epoch 2/10 | Age: 63.15\n",
      "Epoch 3/10 | Age: 50.28\n",
      "Epoch 4/10 | Age: 42.22\n",
      "Epoch 5/10 | Age: 37.50\n",
      "Epoch 6/10 | Age: 33.95\n",
      "Epoch 7/10 | Age: 31.52\n",
      "Epoch 8/10 | Age: 29.40\n",
      "Epoch 9/10 | Age: 27.39\n",
      "Epoch 10/10 | Age: 26.08\n",
      "\n",
      "Image 3/5:\n",
      "Epoch 1/10 | Age: 79.41\n",
      "Epoch 2/10 | Age: 61.66\n",
      "Epoch 3/10 | Age: 53.21\n",
      "Epoch 4/10 | Age: 47.70\n",
      "Epoch 5/10 | Age: 41.20\n",
      "Epoch 6/10 | Age: 35.12\n",
      "Epoch 7/10 | Age: 30.48\n",
      "Epoch 8/10 | Age: 26.96\n",
      "Epoch 9/10 | Age: 24.66\n",
      "Epoch 10/10 | Age: 22.57\n",
      "\n",
      "Image 4/5:\n",
      "Epoch 1/10 | Age: 80.21\n",
      "Epoch 2/10 | Age: 67.81\n",
      "Epoch 3/10 | Age: 58.34\n",
      "Epoch 4/10 | Age: 50.06\n",
      "Epoch 5/10 | Age: 42.30\n",
      "Epoch 6/10 | Age: 38.08\n",
      "Epoch 7/10 | Age: 34.88\n",
      "Epoch 8/10 | Age: 32.33\n",
      "Epoch 9/10 | Age: 29.89\n",
      "Epoch 10/10 | Age: 27.82\n",
      "\n",
      "Image 5/5:\n",
      "Epoch 1/10 | Age: 65.42\n",
      "Epoch 2/10 | Age: 45.27\n",
      "Epoch 3/10 | Age: 36.16\n",
      "Epoch 4/10 | Age: 30.75\n",
      "Epoch 5/10 | Age: 27.25\n",
      "Epoch 6/10 | Age: 24.12\n",
      "Epoch 7/10 | Age: 22.25\n",
      "Epoch 8/10 | Age: 20.49\n",
      "Epoch 9/10 | Age: 19.39\n",
      "Epoch 10/10 | Age: 17.41\n"
     ]
    }
   ],
   "source": [
    "a = -1 # loss coefficient, incentivize low outputs\n",
    "b = 1\n",
    "lr = 1\n",
    "epochs = 10\n",
    "\n",
    "# image processing for cxr-age\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "imgs = []\n",
    "ages = []\n",
    "\n",
    "# iterate over latent space reps\n",
    "# can't batch :( not enough ram. shut up.\n",
    "for i, lrep in enumerate(lreps):\n",
    "    print(f'\\nImage {i + 1}/{len(lreps)}:')\n",
    "\n",
    "    lrep_par = nn.Parameter(lrep.clone())\n",
    "    opt = torch.optim.AdamW([lrep_par], lr=lr)\n",
    "\n",
    "    imgs_batch = []\n",
    "    ages_batch = []\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # decode latent space rep\n",
    "        img_orig = cheff_ae.decode(lrep_par)\n",
    "\n",
    "        # pass img through cxrage model\n",
    "        img = preprocess(img_orig)\n",
    "        pred = cxr_age.model(img)\n",
    "        loss = loss_fn(a, pred, b, lrep_par)\n",
    "\n",
    "        # optimize latent rep\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # store image, age prediction\n",
    "        imgs_batch.append(img_orig)\n",
    "        ages_batch.append(age_fn(pred).item())\n",
    "\n",
    "        print(f'Epoch {epoch + 1}/{epochs} | Age: {ages_batch[-1]:.2f}')\n",
    "\n",
    "    imgs.append(imgs_batch)\n",
    "    ages.append(ages_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot each img and age\n",
    "\n",
    "for i, (img, age) in enumerate(zip(imgs, ages)):\n",
    "    fig, ax = plt.subplots(1, len(img), figsize=(20, 20)) \n",
    "\n",
    "    for j, (img, age) in enumerate(zip(img, age)):\n",
    "        img_d = img.detach().cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "        img_d = (img_d - img_d.min()) / (img_d.max() - img_d.min())\n",
    "        \n",
    "        ax[j].imshow(img_d)\n",
    "        ax[j].axis('off')\n",
    "        ax[j].set_title(f'Age: {age:.2f}', fontsize=12)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    plt.tight_layout(pad=0.5)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f'progs/prog_{i + 1}.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create animation\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "for i, (img, age) in enumerate(zip(imgs, ages)):\n",
    "    fig, ax = plt.subplots(figsize=(2.56, 2.56))  # Assuming 256x256 images\n",
    "\n",
    "    ims = []\n",
    "    for img, age in zip(img, age):\n",
    "        img_d = img.detach().cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "        img_d = (img_d - img_d.min()) / (img_d.max() - img_d.min())\n",
    "        \n",
    "        im = ax.imshow(img_d, animated=True)\n",
    "        text = ax.text(0.21, 0.94, f'Age: {age:.2f}', ha='center', va='center', \n",
    "                       color='red', fontsize=12, transform=ax.transAxes)\n",
    "        \n",
    "        ax.axis('off')\n",
    "        plt.tight_layout(pad=0.4)\n",
    "        ims.append([im, text])\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "    ani.save(f'vids/vid_{i + 1}.mp4', writer='ffmpeg', fps=1, dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original, final, and difference\n",
    "\n",
    "for i, (img, age) in enumerate(zip(imgs, ages)):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "\n",
    "    # original\n",
    "    img_od = img[0].detach().cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "    img_od = (img_od - img_od.min()) / (img_od.max() - img_od.min())\n",
    "    ax[0].imshow(img_od)\n",
    "    ax[0].set_title(f'Original, Age: {age[0]:.2f}', fontsize=18)\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # final\n",
    "    img_fd = img[-1].detach().cpu().numpy().squeeze().transpose(1, 2, 0)\n",
    "    img_fd = (img_fd - img_fd.min()) / (img_fd.max() - img_fd.min())\n",
    "    ax[1].imshow(img_fd)\n",
    "    ax[1].set_title(f'Final, Age: {age[-1]:.2f}', fontsize=18)\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    # difference\n",
    "    diff = (img[-1] - img[0]).detach().cpu().numpy()\n",
    "    diff = diff.squeeze().transpose(1, 2, 0)\n",
    "    diff = diff.mean(-1)\n",
    "    diff_r = np.maximum(diff, 0) # red, positive\n",
    "    diff_b = np.maximum(-diff, 0) # blue, negative\n",
    "    diff = np.stack([diff_r, np.zeros_like(diff), diff_b], axis=-1)\n",
    "    diff = (diff - diff.min()) / (diff.max() - diff.min())\n",
    "    diff = diff * 1.5 # amplify for better visualization\n",
    "    diff = np.clip(diff, 0, 1)\n",
    "    ax[2].imshow(diff)\n",
    "    ax[2].set_title('Difference (Red+, Blue-)', fontsize=18)\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'diffs/diff_{i + 1}.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cheff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
