{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/siamese_env/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Custom Dataset Class\n",
    "class CustomSiameseDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.pairs = []\n",
    "        self._prepare_data()\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.idx_0_images = [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir) if f.endswith('_0.png')]\n",
    "        self.idx_1_images = [os.path.join(self.data_dir, f) for f in os.listdir(self.data_dir) if f.endswith('_1.png')]\n",
    "        self.idx_0_images.sort()\n",
    "        self.idx_1_images.sort()\n",
    "\n",
    "        for idx in range(len(self.idx_0_images)):\n",
    "            self.pairs.append((self.idx_0_images[idx], self.idx_1_images[idx], 1))\n",
    "            random_idx = random.choice([i for i in range(len(self.idx_1_images)) if i != idx])\n",
    "            self.pairs.append((self.idx_0_images[idx], self.idx_1_images[random_idx], 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1_path, img2_path, label = self.pairs[idx]\n",
    "        img1 = Image.open(img1_path).convert(\"L\")\n",
    "        img2 = Image.open(img2_path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32), img1_path, img2_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (img1_batch, img2_batch, label_batch, img1_paths, img2_paths) in enumerate(train_loader):\n",
    "#     print(f\"Batch {i+1}:\")\n",
    "    \n",
    "#     for j in range(len(img1_batch)):  # Loop through the batch\n",
    "#         if label_batch[j].item() != 1:\n",
    "#             continue\n",
    "#         print(f\"  Pair {j+1} in Batch {i+1}:\")\n",
    "#         print(f\"    Image 1: {img1_paths[j]}\")\n",
    "#         print(f\"    Image 2: {img2_paths[j]}\")\n",
    "#         print(f\"    Label: {int(label_batch[j].item())}\")\n",
    "        \n",
    "#         # Optionally, visualize\n",
    "#         show_image_pair(img1_batch[j], img2_batch[j], label_batch[j])\n",
    "        \n",
    "#         if j == 4:  # Limit to 5 pairs for inspection\n",
    "#             break\n",
    "#     break  # Inspect only the first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)  # Embedding size\n",
    "        )\n",
    "\n",
    "    def forward_one(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return F.normalize(x, dim=1)  # Normalize embeddings\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_one(input1)\n",
    "        output2 = self.forward_one(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, margin=1.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss = (label) * torch.pow(euclidean_distance, 2) + \\\n",
    "               (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2)\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_f1_score(model, data_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for (img1, img2, label, _, _) in data_loader:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            distances = F.pairwise_distance(output1, output2)\n",
    "            predictions = (distances < threshold).float()  # Threshold for similarity\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, criterion, and optimizer\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')\n",
    "model = SiameseNetwork().to(device)\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define transforms for images\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = CustomSiameseDataset(data_dir=\"./data\", transform=transform)\n",
    "\n",
    "# Split dataset into train_val and test sets\n",
    "dataset_size = len(dataset)\n",
    "test_size = int(0.2 * dataset_size)  # 20% for testing\n",
    "train_val_size = dataset_size - test_size\n",
    "\n",
    "train_val_dataset, test_dataset = random_split(dataset, [train_val_size, test_size])\n",
    "\n",
    "# Set up k-fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (img1, img2, label, _, _) in data_loader:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            distances = F.pairwise_distance(output1, output2)\n",
    "            predictions = (distances < 0.5).float()  # Threshold for similarity\n",
    "            correct += (predictions == label).sum().item()\n",
    "            total += label.size(0)\n",
    "    return correct / total\n",
    "\n",
    "def evaluate_f1_score(model, data_loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for (img1, img2, label, _, _) in data_loader:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            distances = F.pairwise_distance(output1, output2)\n",
    "            predictions = (distances < threshold).float()  # Threshold for similarity\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold 1/5...\n",
      "Fold 1, Epoch 1/5: Train Loss: 0.2407, Val Loss: 0.2192, Accuracy: 0.6356, Precision: 0.6223, Recall: 0.6548, F1: 0.6381\n",
      "Fold 1, Epoch 2/5: Train Loss: 0.1931, Val Loss: 0.1873, Accuracy: 0.7175, Precision: 0.7459, Recall: 0.6433, F1: 0.6908\n",
      "Fold 1, Epoch 3/5: Train Loss: 0.1710, Val Loss: 0.1712, Accuracy: 0.7650, Precision: 0.7553, Recall: 0.7707, F1: 0.7629\n",
      "Fold 1, Epoch 4/5: Train Loss: 0.1553, Val Loss: 0.1739, Accuracy: 0.7431, Precision: 0.6851, Recall: 0.8815, F1: 0.7710\n",
      "Fold 1, Epoch 5/5: Train Loss: 0.1451, Val Loss: 0.1570, Accuracy: 0.7856, Precision: 0.8113, Recall: 0.7338, F1: 0.7706\n",
      "Starting Fold 2/5...\n",
      "Fold 2, Epoch 1/5: Train Loss: 0.2391, Val Loss: 0.2078, Accuracy: 0.6681, Precision: 0.6934, Recall: 0.6117, F1: 0.6500\n",
      "Fold 2, Epoch 2/5: Train Loss: 0.1964, Val Loss: 0.1802, Accuracy: 0.7362, Precision: 0.7487, Recall: 0.7171, F1: 0.7326\n",
      "Fold 2, Epoch 3/5: Train Loss: 0.1695, Val Loss: 0.1662, Accuracy: 0.7762, Precision: 0.8077, Recall: 0.7295, F1: 0.7666\n",
      "Fold 2, Epoch 4/5: Train Loss: 0.1568, Val Loss: 0.1530, Accuracy: 0.8063, Precision: 0.8238, Recall: 0.7829, F1: 0.8028\n",
      "Fold 2, Epoch 5/5: Train Loss: 0.1444, Val Loss: 0.1623, Accuracy: 0.7738, Precision: 0.7992, Recall: 0.7357, F1: 0.7661\n",
      "Starting Fold 3/5...\n",
      "Fold 3, Epoch 1/5: Train Loss: 0.2411, Val Loss: 0.2085, Accuracy: 0.6637, Precision: 0.6529, Recall: 0.7220, F1: 0.6857\n",
      "Fold 3, Epoch 2/5: Train Loss: 0.1930, Val Loss: 0.1792, Accuracy: 0.7456, Precision: 0.7128, Recall: 0.8364, F1: 0.7697\n",
      "Fold 3, Epoch 3/5: Train Loss: 0.1705, Val Loss: 0.1735, Accuracy: 0.7606, Precision: 0.7771, Recall: 0.7417, F1: 0.7590\n",
      "Fold 3, Epoch 4/5: Train Loss: 0.1533, Val Loss: 0.1628, Accuracy: 0.7700, Precision: 0.7690, Recall: 0.7823, F1: 0.7756\n",
      "Fold 3, Epoch 5/5: Train Loss: 0.1430, Val Loss: 0.1515, Accuracy: 0.8025, Precision: 0.8223, Recall: 0.7798, F1: 0.8005\n",
      "Starting Fold 4/5...\n",
      "Fold 4, Epoch 1/5: Train Loss: 0.2403, Val Loss: 0.2117, Accuracy: 0.6656, Precision: 0.6102, Recall: 0.8398, F1: 0.7068\n",
      "Fold 4, Epoch 2/5: Train Loss: 0.1942, Val Loss: 0.1828, Accuracy: 0.7281, Precision: 0.7033, Recall: 0.7500, F1: 0.7259\n",
      "Fold 4, Epoch 3/5: Train Loss: 0.1712, Val Loss: 0.1662, Accuracy: 0.7669, Precision: 0.7739, Recall: 0.7266, F1: 0.7495\n",
      "Fold 4, Epoch 4/5: Train Loss: 0.1552, Val Loss: 0.1650, Accuracy: 0.7700, Precision: 0.7439, Recall: 0.7943, F1: 0.7683\n",
      "Fold 4, Epoch 5/5: Train Loss: 0.1454, Val Loss: 0.1553, Accuracy: 0.8063, Precision: 0.7759, Recall: 0.8385, F1: 0.8060\n",
      "Starting Fold 5/5...\n",
      "Fold 5, Epoch 1/5: Train Loss: 0.2354, Val Loss: 0.2038, Accuracy: 0.6794, Precision: 0.6996, Recall: 0.6453, F1: 0.6714\n",
      "Fold 5, Epoch 2/5: Train Loss: 0.1852, Val Loss: 0.1867, Accuracy: 0.7231, Precision: 0.8000, Recall: 0.6059, F1: 0.6896\n",
      "Fold 5, Epoch 3/5: Train Loss: 0.1662, Val Loss: 0.1693, Accuracy: 0.7694, Precision: 0.7526, Recall: 0.8128, F1: 0.7815\n",
      "Fold 5, Epoch 4/5: Train Loss: 0.1520, Val Loss: 0.1660, Accuracy: 0.7656, Precision: 0.7849, Recall: 0.7414, F1: 0.7625\n",
      "Fold 5, Epoch 5/5: Train Loss: 0.1440, Val Loss: 0.1551, Accuracy: 0.7944, Precision: 0.8475, Recall: 0.7254, F1: 0.7817\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "num_epochs = 5\n",
    "fold_train_losses = []\n",
    "fold_val_losses = []\n",
    "fold_metrics = []  # List to store metrics for each fold and epoch\n",
    "\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(range(len(train_val_dataset)))):\n",
    "    print(f\"Starting Fold {fold+1}/{k_folds}...\")\n",
    "\n",
    "    # Create DataLoaders for this fold\n",
    "    train_subset = Subset(train_val_dataset, train_indices)\n",
    "    val_subset = Subset(train_val_dataset, val_indices)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Reinitialize model and optimizer for each fold\n",
    "    model = SiameseNetwork().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Track losses for this fold\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    fold_epoch_metrics = []  # Store metrics for each epoch\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for (img1, img2, label, _, _) in train_loader:\n",
    "            img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            loss = criterion(output1, output2, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        train_losses.append(epoch_train_loss / len(train_loader))\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for (img1, img2, label, _, _) in val_loader:\n",
    "                img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "                output1, output2 = model(img1, img2)\n",
    "                loss = criterion(output1, output2, label)\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "                # Collect predictions for metrics\n",
    "                distances = F.pairwise_distance(output1, output2)\n",
    "                predictions = (distances < 0.5).float()  # Threshold for similarity\n",
    "                all_labels.extend(label.cpu().numpy())\n",
    "                all_predictions.extend(predictions.cpu().numpy())\n",
    "        val_losses.append(epoch_val_loss / len(val_loader))\n",
    "\n",
    "        # Calculate metrics\n",
    "        accuracy = sum(np.array(all_predictions) == np.array(all_labels)) / len(all_labels)\n",
    "        precision = precision_score(all_labels, all_predictions)\n",
    "        recall = recall_score(all_labels, all_predictions)\n",
    "        f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "        # Save metrics for this epoch\n",
    "        fold_epoch_metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"train_loss\": train_losses[-1],\n",
    "            \"val_loss\": val_losses[-1],\n",
    "        })\n",
    "\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}/{num_epochs}: \"\n",
    "              f\"Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, \"\n",
    "              f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, \"\n",
    "              f\"Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "\n",
    "    # Store fold metrics\n",
    "    fold_train_losses.append(train_losses)\n",
    "    fold_val_losses.append(val_losses)\n",
    "    fold_metrics.append(fold_epoch_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross-Validated Metrics:\n",
      "accuracy      0.792500\n",
      "precision     0.811231\n",
      "recall        0.762646\n",
      "f1            0.784983\n",
      "train_loss    0.144374\n",
      "val_loss      0.156239\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def compute_average_cross_validated_metrics(fold_metrics):\n",
    "    metrics_list = []\n",
    "    for fold_idx, metrics in enumerate(fold_metrics):\n",
    "        for epoch_metrics in metrics:\n",
    "            metrics_list.append({\n",
    "                \"Fold\": fold_idx + 1,\n",
    "                **epoch_metrics  # Unpack epoch metrics\n",
    "            })\n",
    "    \n",
    "    metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "    # Compute average metrics for the last epoch of each fold\n",
    "    avg_metrics = metrics_df.groupby(\"Fold\").last().mean()\n",
    "    avg_metrics = avg_metrics[[\"accuracy\", \"precision\", \"recall\", \"f1\", \"train_loss\", \"val_loss\"]]\n",
    "    return avg_metrics\n",
    "\n",
    "average_cv_metrics = compute_average_cross_validated_metrics(fold_metrics)\n",
    "print(\"Average Cross-Validated Metrics:\")\n",
    "print(average_cv_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_metrics(model, test_loader):\n",
    "    precision, recall, f1 = evaluate_f1_score(model, test_loader)\n",
    "    accuracy = calculate_accuracy(model, test_loader)\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Metrics:\n",
      "{'accuracy': 0.818, 'precision': 0.8171206225680934, 'recall': 0.8267716535433071, 'f1': 0.821917808219178}\n"
     ]
    }
   ],
   "source": [
    "final_train_loader = DataLoader(train_val_dataset, batch_size=32, shuffle=True)\n",
    "final_model = SiameseNetwork().to(device)\n",
    "final_optimizer = torch.optim.Adam(final_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    final_model.train()\n",
    "    for (img1, img2, label, _, _) in final_train_loader:\n",
    "        img1, img2, label = img1.to(device), img2.to(device), label.to(device)\n",
    "        output1, output2 = final_model(img1, img2)\n",
    "        loss = criterion(output1, output2, label)\n",
    "        final_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        final_optimizer.step()\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "test_metrics = compute_test_metrics(final_model, test_loader)\n",
    "\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(test_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a function to process one random example\n",
    "def process_true_random_example(test_loader, model, device):\n",
    "    # Flatten all label 1 pairs from the entire test set\n",
    "    all_label_1_pairs = []\n",
    "    all_pairs = []\n",
    "\n",
    "    for batch_idx, (batch_img1, batch_img2, batch_labels, _, _) in enumerate(test_loader):\n",
    "        for idx in range(len(batch_labels)):\n",
    "            pair = (batch_img1[idx], batch_img2[idx], batch_labels[idx])\n",
    "            all_pairs.append(pair)  # Add every pair\n",
    "            if batch_labels[idx].item() == 1:  # Add label 1 pairs\n",
    "                all_label_1_pairs.append(pair)\n",
    "\n",
    "    if not all_label_1_pairs:\n",
    "        raise ValueError(\"No label 1 pairs found in the test set!\")\n",
    "\n",
    "    # Randomly select one true original-optimized pair (label 1)\n",
    "    true_pair = random.choice(all_label_1_pairs)\n",
    "    true_original_img, optimized_img, _ = true_pair\n",
    "\n",
    "    # Select 3 unique distractors that do not include the true original\n",
    "    distractor_imgs = []\n",
    "    while len(distractor_imgs) < 3:\n",
    "        random_pair = random.choice(all_pairs)\n",
    "        random_distractor = random_pair[0]  # Use the first image as the distractor\n",
    "        # Ensure the random distractor is not the true original and not a duplicate\n",
    "        if torch.equal(true_original_img, random_distractor):\n",
    "            continue  # Skip if it's the true original\n",
    "        if any(torch.equal(random_distractor, distractor) for distractor in distractor_imgs):\n",
    "            continue  # Skip if it's already in the distractor list\n",
    "        distractor_imgs.append(random_distractor)\n",
    "\n",
    "    # Create pairs: (true original + optimized) and (randoms + optimized)\n",
    "    pairs = [(true_original_img, optimized_img)] + [(distractor, optimized_img) for distractor in distractor_imgs]\n",
    "\n",
    "    # Pass through the model and calculate distances\n",
    "    model.eval()\n",
    "    distances = []\n",
    "    with torch.no_grad():\n",
    "        for img1, img2 in pairs:\n",
    "            img1, img2 = img1.unsqueeze(0).to(device), img2.unsqueeze(0).to(device)\n",
    "            output1, output2 = model(img1, img2)\n",
    "            distances.append(F.pairwise_distance(output1, output2).item())\n",
    "\n",
    "    # Convert distances to probabilities\n",
    "    probs = F.softmax(-torch.tensor(distances), dim=0).tolist()\n",
    "\n",
    "    # Return the processed data\n",
    "    return {\n",
    "        \"true_original_img\": true_original_img,\n",
    "        \"optimized_img\": optimized_img,\n",
    "        \"distractor_imgs\": distractor_imgs,\n",
    "        \"distances\": distances,\n",
    "        \"probs\": probs,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Use this function for random selection\n",
    "result = process_true_random_example(test_loader, model, device)\n",
    "\n",
    "# Visualize the result\n",
    "true_original_img = result[\"true_original_img\"]\n",
    "optimized_img = result[\"optimized_img\"]\n",
    "distractor_imgs = result[\"distractor_imgs\"]\n",
    "distances = result[\"distances\"]  # Use distances\n",
    "probs = result[\"probs\"]          # Use probabilities\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(18, 5))\n",
    "\n",
    "# Display the optimized image\n",
    "axes[0].imshow(optimized_img.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "axes[0].set_title(\"Optimized Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Display true original and distractor images with distances and probabilities\n",
    "for j, (img, dist, prob) in enumerate(zip([true_original_img] + distractor_imgs, distances, probs)):\n",
    "    if j == 0:  # True original\n",
    "        axes[j + 1].imshow(img.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "        axes[j + 1].set_title(f\"Original\\nDist: {dist:.2f}\\nProb: {prob:.2f}\", color=\"green\")\n",
    "    else:  # Distractors\n",
    "        axes[j + 1].imshow(img.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "        axes[j + 1].set_title(f\"Dist: {dist:.2f}\\nProb: {prob:.2f}\", color=\"red\")\n",
    "    axes[j + 1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
